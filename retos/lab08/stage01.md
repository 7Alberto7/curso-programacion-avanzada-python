## âœ… Resoluciones Â· Fase 1 â€” Contador sin Lock

---

### ğŸ”¸ Reto 1 â€” Observa cÃ³mo falla un contador sin protecciÃ³n

#### ğŸ§  Proceso mental

Queremos probar que, sin protecciÃ³n, varios procesos escribiendo en el mismo `Value` provocan errores silenciosos. Esto es una condiciÃ³n de carrera. El valor final **no serÃ¡ fiable**.

#### ğŸ§© Pasos:

1. AsegÃºrate de tener la funciÃ³n `incrementar()` en `app/procesos.py` tal como estÃ¡:

```python
def incrementar(contador: Value, n_iter: int = 100_000, lock=None) -> None:
    for _ in range(n_iter):
        contador.value += 1  # sin lock
```

2. En `main.py`, crea un `Value` entero compartido:

```python
contador = Value('i', 0)
```

3. Lanza 4 procesos que llamen a `incrementar_sin_lock(contador)`:

```python
procesos = [Process(target=incrementar_sin_lock, args=(contador,)) for _ in range(4)]
```

4. Llama a `.start()` y `.join()` como siempre:

```python
for p in procesos: p.start()
for p in procesos: p.join()
```

5. Imprime el valor final del contador:

```python
print(f"Fase 1 (sin lock) â†’ contador: {contador.value} (esperado: 400000)")
```

#### ğŸ§ª ValidaciÃ³n:

* La salida mostrarÃ¡ un nÃºmero **menor a 400000**, por ejemplo:

```
Fase 1 (sin lock) â†’ contador: 274183 (esperado: 400000)
```

#### ğŸ’¡ Aprendo que:

* Las condiciones de carrera **no se notan con errores**, pero destruyen los resultados.
* Python no protege los accesos a `Value` automÃ¡ticamente â†’ el programador debe hacerlo.

---

### ğŸ”¸ Reto 2 â€” Provoca mÃ¡s fallos aumentando la presiÃ³n

#### ğŸ§  Proceso mental

Si aumentamos el nÃºmero de iteraciones o procesos, **amplificamos el problema**. Con mÃ¡s competencia por el mismo recurso, hay mÃ¡s errores.

#### ğŸ§© Opciones:

**OpciÃ³n A:** Aumenta `n_iter` en `incrementar()`:

```python
incrementar(contador, n_iter=1_000_000)
```

**OpciÃ³n B:** Aumenta el nÃºmero de procesos a 8:

```python
procesos = [Process(target=incrementar_sin_lock, args=(contador,)) for _ in range(8)]
```

**Opcional:** Cambia el tipo de dato a `long`:

```python
contador = Value('l', 0)  # tambiÃ©n da error sin lock
```

#### ğŸ§ª ValidaciÃ³n:

* El valor final serÃ¡ **aÃºn mÃ¡s incorrecto** (por ejemplo, 512393 en lugar de 800000).
* A veces cambia en cada ejecuciÃ³n â†’ no hay estabilidad.

#### ğŸ’¡ Aprendo que:

* El problema **se intensifica** con mayor paralelismo.
* Usar `long` en lugar de `int` **no soluciona nada**: el error estÃ¡ en la concurrencia.

---

### ğŸ”¸ Reto 3 â€” Mide el tiempo total sin Lock (baseline de rendimiento)

#### ğŸ§  Proceso mental

Queremos establecer un **tiempo base** de ejecuciÃ³n **sin lock**, para comparar despuÃ©s con la versiÃ³n sincronizada en la Fase 2.

#### ğŸ§© Pasos:

1. Importa `perf_counter` al principio del archivo:

```python
from time import perf_counter
```

2. Rodea tu llamada a `fase1_contador_sin_lock()` con:

```python
inicio = perf_counter()
fase1_contador_sin_lock()
fin = perf_counter()
print(f"â±ï¸ DuraciÃ³n sin lock: {fin - inicio:.4f} segundos")
```

3. Ejecuta varias veces para tener un promedio orientativo.

#### ğŸ§ª ValidaciÃ³n:

```bash
Fase 1 (sin lock) â†’ contador: 297001 (esperado: 400000)
â±ï¸ DuraciÃ³n sin lock: 0.2135 segundos
```

#### ğŸ’¡ Aprendo que:

* La versiÃ³n sin lock es **rÃ¡pida pero incorrecta**.
* La comparaciÃ³n de rendimiento solo tiene sentido si la salida es vÃ¡lida.