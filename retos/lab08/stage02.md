## âœ… Resoluciones Â· Fase 2 â€” Contador con Lock

---

### ğŸ”¸ Reto 1 â€” Â¿Funciona el Lock? Verifica el resultado exacto

#### ğŸ§  Proceso mental

Queremos comprobar que, si usamos `multiprocessing.Lock`, **la condiciÃ³n de carrera desaparece** y el contador llega siempre al valor esperado. Es lo mÃ­nimo que deberÃ­amos garantizar.

#### ğŸ§© Pasos:

1. AsegÃºrate de que en `main.py` estÃ¡s usando:

```python
contador = Value('i', 0)
lock = Lock()
```

2. Al crear cada proceso, pÃ¡sale el `lock`:

```python
procesos = [
    Process(target=incrementar, args=(contador, 100_000, lock))
    for _ in range(4)
]
```

3. En `app/procesos.py`, protege el incremento:

```python
for _ in range(n_iter):
    with lock:
        contador.value += 1
```

4. Ejecuta `fase2_contador_con_lock()` y compara con `esperado = 400000`.

#### ğŸ§ª ValidaciÃ³n:

```bash
Fase 2 (con lock) â†’ contador: 400000  (esperado: 400000)
```

âœ… **Siempre coincide**, incluso al repetir mÃºltiples veces.

#### ğŸ’¡ Aprendo que:

* El `Lock` impide que dos procesos accedan a la misma secciÃ³n crÃ­tica al mismo tiempo.
* Concurrencia sin sincronizaciÃ³n = resultados no confiables.

---

### ğŸ”¸ Reto 2 â€” Â¿CuÃ¡nto cuesta el Lock? Mide el tiempo

#### ğŸ§  Proceso mental

Ahora que sabemos que `Lock` resuelve el problema, queremos saber **quÃ© impacto tiene en el rendimiento** respecto a la versiÃ³n sin lock (Fase 1).

#### ğŸ§© Pasos:

1. Importa al inicio:

```python
from time import perf_counter
```

2. Rodea tu llamada a la Fase 2 con mediciÃ³n:

```python
inicio = perf_counter()
fase2_contador_con_lock()
fin = perf_counter()
print(f"â±ï¸ DuraciÃ³n con lock: {fin - inicio:.4f} segundos")
```

3. Compara con el tiempo registrado en la Fase 1.

#### ğŸ§ª Ejemplo:

```
Fase 2 (con lock) â†’ contador: 400000  (esperado: 400000)
â±ï¸ DuraciÃ³n con lock: 0.8012 segundos
```

(Si Fase 1 tardaba \~0.2 s â†’ **4Ã— mÃ¡s lento**, pero correcto.)

#### ğŸ’¡ Aprendo que:

* El uso de locks es **seguro pero mÃ¡s lento**.
* Hay que evaluar **seguridad vs rendimiento** segÃºn el caso.

---

### ğŸ”¸ Reto 3 â€” Â¿QuÃ© pasa si optimizas la secciÃ³n crÃ­tica?

#### ğŸ§  Proceso mental

Bloquear cada incremento con `with lock:` es seguro, pero caro. Podemos **acumular en local** y actualizar el contador global cada cierto tiempo â†’ menos bloqueos, mismo resultado.

#### ğŸ§© Pasos:

1. En `app/procesos.py`, reemplaza esta parte:

```python
for _ in range(n_iter):
    with lock:
        contador.value += 1
```

2. Por esta versiÃ³n optimizada:

```python
local_sum = 0
for i in range(n_iter):
    local_sum += 1
    if i % 1000 == 0:
        with lock:
            contador.value += local_sum
            local_sum = 0

if local_sum:
    with lock:
        contador.value += local_sum
```

3. Ejecuta como siempre. El valor debe seguir siendo correcto.

#### ğŸ§ª ValidaciÃ³n:

```
Fase 2 (con lock optimizado) â†’ contador: 400000  (esperado: 400000)
â±ï¸ DuraciÃ³n con lock: 0.4253 segundos
```

(Â¡MÃ¡s rÃ¡pido que el lock tradicional!)

#### ğŸ’¡ Aprendo que:

* **No todo debe estar protegido** con lock: solo lo crÃ­tico.
* Optimizar la secciÃ³n crÃ­tica mejora mucho el rendimiento sin sacrificar seguridad.